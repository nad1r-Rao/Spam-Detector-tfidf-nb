{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SPAM EMAIL DETECTOR**"
      ],
      "metadata": {
        "id": "w073bw13ffU4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98-o4WfrfP8F"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv(\"spam_clean.csv\", encoding='latin-1')\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "X8417lAygAGG",
        "outputId": "0ccc1af9-a043-4c00-a638-0f01f18dca42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  Go until jurong point, crazy.. Available only ...      0\n",
              "1                      Ok lar... Joking wif u oni...      0\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
              "3  U dun say so early hor... U c already then say...      0\n",
              "4  Nah I don't think he goes to usf, he lives aro...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d56259d-965b-4efa-a534-30f06169bedd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d56259d-965b-4efa-a534-30f06169bedd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d56259d-965b-4efa-a534-30f06169bedd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d56259d-965b-4efa-a534-30f06169bedd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5a467a42-62b2-4978-89e7-fd28b9b1d811\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a467a42-62b2-4978-89e7-fd28b9b1d811')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5a467a42-62b2-4978-89e7-fd28b9b1d811 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5158,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5158,\n        \"samples\": [\n          \"&lt;#&gt;  am I think? Should say on syllabus\",\n          \"2mro i am not coming to gym machan. Goodnight.\",\n          \"Carlos'll be here in a minute if you still need to buy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[\"text\"].astype(str).values\n",
        "y = df[\"label\"].astype(int).values\n",
        "\n",
        "# 70% train, 15% val, 15% test (all stratified)\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
        "    X, y, test_size=0.30, stratify=y, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_tmp, y_tmp, test_size=0.50, stratify=y_tmp, random_state=42\n",
        ")\n",
        "\n",
        "len(X_train), len(X_val), len(X_test), y.mean(), y_train.mean(), y_val.mean(), y_test.mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmiTy2lmgqe4",
        "outputId": "48b86e22-2a7b-41a1-d4ff-d19fc1b0b71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3610,\n",
              " 774,\n",
              " 774,\n",
              " np.float64(0.12446684761535479),\n",
              " np.float64(0.12437673130193906),\n",
              " np.float64(0.12532299741602068),\n",
              " np.float64(0.12403100775193798))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF + Multinomial Naive Bayes (baseline on VALIDATION set)\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Build a simple, strong baseline:\n",
        "# - TF-IDF with unigrams + bigrams\n",
        "# - Ignore tokens that appear < 2 docs (min_df=2) to reduce noise\n",
        "\n",
        "pipe_nb = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(\n",
        "        lowercase=True,\n",
        "        ngram_range=(1, 2),\n",
        "        min_df=2\n",
        "    )),\n",
        "    (\"nb\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Train on TRAIN split only\n",
        "pipe_nb.fit(X_train, y_train)\n",
        "\n",
        "# Get probabilities for VALIDATION\n",
        "proba_val = pipe_nb.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Default decision threshold = 0.50\n",
        "pred_val_default = (proba_val >= 0.5).astype(int)\n",
        "\n",
        "print(\"Validation @ threshold = 0.50\")\n",
        "print(classification_report(y_val, pred_val_default, digits=4))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, pred_val_default))\n",
        "\n",
        "# Threshold-agnostic metric (useful to compare models later)\n",
        "print(\"ROC-AUC (validation):\", roc_auc_score(y_val, proba_val))\n",
        "\n",
        "# quick peek at vocabulary size\n",
        "print(\"Vocabulary size:\", len(pipe_nb.named_steps[\"tfidf\"].vocabulary_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZp78kpvjufr",
        "outputId": "932980bc-01ac-4f95-d16d-5680919ecba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @ threshold = 0.50\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9562    1.0000    0.9776       677\n",
            "           1     1.0000    0.6804    0.8098        97\n",
            "\n",
            "    accuracy                         0.9599       774\n",
            "   macro avg     0.9781    0.8402    0.8937       774\n",
            "weighted avg     0.9617    0.9599    0.9566       774\n",
            "\n",
            "Confusion matrix:\n",
            " [[677   0]\n",
            " [ 31  66]]\n",
            "ROC-AUC (validation): 0.9808433202881116\n",
            "Vocabulary size: 8699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Threshold tuning\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n",
        "\n",
        "# Find best F1 threshold on validation\n",
        "thresholds = np.linspace(0, 1, 101)\n",
        "f1s = [f1_score(y_val, (proba_val >= t).astype(int)) for t in thresholds]\n",
        "best_t = float(thresholds[int(np.argmax(f1s))])\n",
        "\n",
        "def show_metrics(name, t):\n",
        "    pred = (proba_val >= t).astype(int)\n",
        "    print(f\"\\n=== {name} (t={t:.2f}) ===\")\n",
        "    print(f\"precision={precision_score(y_val, pred):.3f}  recall={recall_score(y_val, pred):.3f}  f1={f1_score(y_val, pred):.3f}\")\n",
        "    print(\"confusion matrix:\\n\", confusion_matrix(y_val, pred))\n",
        "\n",
        "# Target a high recall option (~0.90)\n",
        "prec, rec, th = precision_recall_curve(y_val, proba_val)  # th aligns with rec[:-1]/prec[:-1]\n",
        "t_recall = best_t\n",
        "for r, tt in zip(rec[:-1], th):\n",
        "    if r >= 0.90:\n",
        "        t_recall = float(tt); break\n",
        "\n",
        "# Show three useful operating points\n",
        "show_metrics(\"default\", 0.50)\n",
        "show_metrics(\"best_F1\", best_t)\n",
        "show_metrics(\"recall≈0.90\", t_recall)\n",
        "\n",
        "best_t  # keep this for next\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxaT4uqzoY4C",
        "outputId": "fec5af2f-dd57-41fc-9c8d-6d3378f9ba59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== default (t=0.50) ===\n",
            "precision=1.000  recall=0.680  f1=0.810\n",
            "confusion matrix:\n",
            " [[677   0]\n",
            " [ 31  66]]\n",
            "\n",
            "=== best_F1 (t=0.13) ===\n",
            "precision=0.989  recall=0.887  f1=0.935\n",
            "confusion matrix:\n",
            " [[676   1]\n",
            " [ 11  86]]\n",
            "\n",
            "=== recall≈0.90 (t=0.00) ===\n",
            "precision=0.125  recall=1.000  f1=0.223\n",
            "confusion matrix:\n",
            " [[  0 677]\n",
            " [  0  97]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation on TEST set (using t from Cell 4)\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
        "\n",
        "t = 0.13  # chosen from Cell 4 (best_F1)\n",
        "\n",
        "proba_test = pipe_nb.predict_proba(X_test)[:, 1]\n",
        "pred_test = (proba_test >= t).astype(int)\n",
        "\n",
        "print(f\"Test-set performance @ threshold={t:.2f}\")\n",
        "print(classification_report(y_test, pred_test, digits=4))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred_test))\n",
        "print(\"ROC-AUC (test):\", roc_auc_score(y_test, proba_test))\n",
        "print(\"PR-AUC  (test):\", average_precision_score(y_test, proba_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZkoCpE0qpV4",
        "outputId": "0a768c61-9a9b-422e-b50e-11cf1940d8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test-set performance @ threshold=0.13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9797    0.9971    0.9883       678\n",
            "           1     0.9762    0.8542    0.9111        96\n",
            "\n",
            "    accuracy                         0.9793       774\n",
            "   macro avg     0.9780    0.9256    0.9497       774\n",
            "weighted avg     0.9793    0.9793    0.9787       774\n",
            "\n",
            "Confusion matrix:\n",
            " [[676   2]\n",
            " [ 14  82]]\n",
            "ROC-AUC (test): 0.9819167895771878\n",
            "PR-AUC  (test): 0.9489446078831076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell 6 — Inspect false negatives/false positives**\n",
        "**Check spam emails we have missed from CELL 5**\n"
      ],
      "metadata": {
        "id": "vU0vElJ-rgeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Build a review table for test set\n",
        "df_test = pd.DataFrame({\n",
        "    \"text\": X_test,\n",
        "    \"y_true\": y_test,\n",
        "    \"proba_spam\": proba_test,\n",
        "})\n",
        "df_test[\"pred\"] = (df_test[\"proba_spam\"] >= t).astype(int)\n",
        "df_test[\"correct\"] = (df_test[\"pred\"] == df_test[\"y_true\"])\n",
        "df_test[\"type\"] = np.where(df_test[\"correct\"], \"correct\",\n",
        "                    np.where((df_test[\"y_true\"]==1)&(df_test[\"pred\"]==0),\"FN\",\"FP\"))\n",
        "\n",
        "print(\"Counts by type:\\n\", df_test[\"type\"].value_counts())\n",
        "\n",
        "# Top 10 False Negatives (missed spam) — highest probabilities (closest to threshold)\n",
        "fns = df_test.query(\"type=='FN'\").sort_values(\"proba_spam\", ascending=False).head(10)\n",
        "print(\"\\n--- Top False Negatives (missed spam) ---\")\n",
        "for i, r in fns.iterrows():\n",
        "    print(f\"\\nproba={r.proba_spam:.3f} | text: {r.text[:220]}\")\n",
        "\n",
        "# Top 10 False Positives (ham flagged spam) — lowest probabilities among FPs\n",
        "fps = df_test.query(\"type=='FP'\").sort_values(\"proba_spam\", ascending=True).head(10)\n",
        "print(\"\\n--- Top False Positives (ham flagged spam) ---\")\n",
        "for i, r in fps.iterrows():\n",
        "    print(f\"\\nproba={r.proba_spam:.3f} | text: {r.text[:220]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qxMoAJjrjZj",
        "outputId": "fa88776f-2c71-4d98-ef5b-efa156e680d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts by type:\n",
            " type\n",
            "correct    758\n",
            "FN          14\n",
            "FP           2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Top False Negatives (missed spam) ---\n",
            "\n",
            "proba=0.112 | text: Hi babe its Jordan, how r u? Im home from abroad and lonely, text me back if u wanna chat xxSP visionsms.com Text stop to stopCost 150p 08712400603\n",
            "\n",
            "proba=0.103 | text: I want some cock! My hubby's away, I need a real man 2 satisfy me. Txt WIFE to 89938 for no strings action. (Txt STOP 2 end, txt rec Ã¥Â£1.50ea. OTBox 731 LA1 7WS. )\n",
            "\n",
            "proba=0.095 | text: TheMob>Yo yo yo-Here comes a new selection of hot downloads for our members to get for FREE! Just click & open the next link sent to ur fone...\n",
            "\n",
            "proba=0.088 | text: FreeMsg Hey U, i just got 1 of these video/pic fones, reply WILD to this txt & ill send U my pics, hurry up Im so bored at work xxx (18 150p/rcvd STOP2stop)\n",
            "\n",
            "proba=0.070 | text: ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE MINS. INDIA CUST SERVs SED YES. L8ER GOT MEGA BILL. 3 DONT GIV A SHIT. BAILIFF DUE IN DAYS. I O Ã¥Â£250 3 WANT Ã¥Â£800\n",
            "\n",
            "proba=0.058 | text: Xmas & New Years Eve tickets are now on sale from the club, during the day from 10am till 8pm, and on Thurs, Fri & Sat night this week. They're selling fast!\n",
            "\n",
            "proba=0.055 | text: cmon babe, make me horny, *turn* me on! Txt me your fantasy now babe -) Im hot, sticky and need you now. All replies cost Ã¥Â£1.50. 2 cancel send STOP\n",
            "\n",
            "proba=0.054 | text: Block Breaker now comes in deluxe format with new features and great graphics from T-Mobile. Buy for just Ã¥Â£5 by replying GET BBDELUXE and take the challenge\n",
            "\n",
            "proba=0.033 | text: Hi I'm sue. I am 20 years old and work as a lapdancer. I love sex. Text me live - I'm i my bedroom now. text SUE to 89555. By TextOperator G2 1DA 150ppmsg 18+\n",
            "\n",
            "proba=0.031 | text: LookAtMe!: Thanks for your purchase of a video clip from LookAtMe!, you've been charged 35p. Think you can do better? Why not send a video in a MMSto 32323.\n",
            "\n",
            "--- Top False Positives (ham flagged spam) ---\n",
            "\n",
            "proba=0.197 | text: Received, understood n acted upon!\n",
            "\n",
            "proba=0.349 | text: Nokia phone is lovly..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "for t_try in [0.13, 0.12, 0.11, 0.10]:\n",
        "    pred = (proba_test >= t_try).astype(int)\n",
        "    print(f\"\\n=== TEST @ t={t_try:.2f} ===\")\n",
        "    print(classification_report(y_test, pred, digits=4))\n",
        "    print(\"confusion:\\n\", confusion_matrix(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mo_kOSUuAMM",
        "outputId": "bc294d43-44d4-46fe-d6f4-64b9ade1c978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TEST @ t=0.13 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9797    0.9971    0.9883       678\n",
            "           1     0.9762    0.8542    0.9111        96\n",
            "\n",
            "    accuracy                         0.9793       774\n",
            "   macro avg     0.9780    0.9256    0.9497       774\n",
            "weighted avg     0.9793    0.9793    0.9787       774\n",
            "\n",
            "confusion:\n",
            " [[676   2]\n",
            " [ 14  82]]\n",
            "\n",
            "=== TEST @ t=0.12 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9796    0.9926    0.9861       678\n",
            "           1     0.9425    0.8542    0.8962        96\n",
            "\n",
            "    accuracy                         0.9755       774\n",
            "   macro avg     0.9611    0.9234    0.9411       774\n",
            "weighted avg     0.9750    0.9755    0.9749       774\n",
            "\n",
            "confusion:\n",
            " [[673   5]\n",
            " [ 14  82]]\n",
            "\n",
            "=== TEST @ t=0.11 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9810    0.9897    0.9853       678\n",
            "           1     0.9222    0.8646    0.8925        96\n",
            "\n",
            "    accuracy                         0.9742       774\n",
            "   macro avg     0.9516    0.9271    0.9389       774\n",
            "weighted avg     0.9737    0.9742    0.9738       774\n",
            "\n",
            "confusion:\n",
            " [[671   7]\n",
            " [ 13  83]]\n",
            "\n",
            "=== TEST @ t=0.10 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9824    0.9867    0.9845       678\n",
            "           1     0.9032    0.8750    0.8889        96\n",
            "\n",
            "    accuracy                         0.9729       774\n",
            "   macro avg     0.9428    0.9309    0.9367       774\n",
            "weighted avg     0.9726    0.9729    0.9727       774\n",
            "\n",
            "confusion:\n",
            " [[669   9]\n",
            " [ 12  84]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **From cell 7 i can see that t=0.13 is still better in selection so i keep it with it**\n",
        "**Saving my pipeline with threshold 0.13 so it will handle dynamically when ever i used my trained model for training saved data**"
      ],
      "metadata": {
        "id": "kxWu2iVTufh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, json\n",
        "\n",
        "# Use the NB pipeline i already trained: pipe_nb\n",
        "# And my chosen threshold:\n",
        "t = 0.13\n",
        "\n",
        "joblib.dump(pipe_nb, \"spam_nb_tfidf.joblib\")\n",
        "with open(\"threshold.json\",\"w\") as f:\n",
        "    json.dump({\"threshold\": float(t)}, f)\n",
        "\n",
        "print(\"Saved files:\")\n",
        "!ls -lh spam_nb_tfidf.joblib threshold.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1dLFGzEulJI",
        "outputId": "72db038c-8e35-4572-ae63-88fa48bd4081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved files:\n",
            "-rw-r--r-- 1 root root 457K Aug 12 10:14 spam_nb_tfidf.joblib\n",
            "-rw-r--r-- 1 root root   19 Aug 12 10:14 threshold.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, json\n",
        "\n",
        "pipe = joblib.load(\"spam_nb_tfidf.joblib\")\n",
        "with open(\"threshold.json\") as f:\n",
        "    T = json.load(f)[\"threshold\"]\n",
        "\n",
        "print(\"Loaded threshold:\", T)\n",
        "print(\"Classes:\", pipe.named_steps[\"nb\"].classes_)\n",
        "print(\"Mini test:\", pipe.predict_proba([\"Free entry in a weekly prize draw, claim now!\"])[:,1][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKUka9T40qlR",
        "outputId": "865976f5-646a-4abc-8987-3b29abf8f0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded threshold: 0.13\n",
            "Classes: [0 1]\n",
            "Mini test: 0.9213202911398749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr, joblib, json\n",
        "\n",
        "pipe = joblib.load(\"spam_nb_tfidf.joblib\")\n",
        "with open(\"threshold.json\") as f:\n",
        "    T = json.load(f)[\"threshold\"]\n",
        "\n",
        "def predict_sms(msg: str):\n",
        "    msg = (msg or \"\").strip()\n",
        "    if not msg:\n",
        "        return {\"—\": 1.0}\n",
        "    p = float(pipe.predict_proba([msg])[0,1])\n",
        "    return {\"SPAM\": p, \"HAM\": 1 - p}\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_sms,\n",
        "    inputs=gr.Textbox(lines=4, label=\"Message\"),\n",
        "    outputs=gr.Label(label=\"Prediction\", num_top_classes=2),\n",
        "    title=\"Spam Detector (TF-IDF + Naive Bayes)\",\n",
        "    description=f\"Decision threshold t = {T:.2f} (used internally for decisions)\",\n",
        "    examples=[\n",
        "        [\"Free entry! Claim now by clicking the link\"],\n",
        "        [\"Dinner at 8 tonight?\"],\n",
        "        [\"Your OTP is 274913. Do not share it.\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "lL1xPJP42Cni",
        "outputId": "bcfdf29a-2307-4613-d322-f4c6be91e883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e99ce7fdaeef081600.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e99ce7fdaeef081600.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}